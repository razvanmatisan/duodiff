{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.early_exit import EarlyExitUViT, OldEarlyExitUViT\n",
    "from models.uvit import UViT\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda:0\"\n",
    "    try:\n",
    "        if torch.backends.mps.is_available():\n",
    "            return \"mps\"\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    return \"cpu\"\n",
    "\n",
    "device = get_device()\n",
    "betas = torch.linspace(1e-4, 0.02, 1000).to(device)\n",
    "alphas = 1 - betas\n",
    "alphas_bar = torch.cumprod(alphas, dim=0)\n",
    "alphas_bar_previous = torch.cat([torch.tensor([1.0], device=device), alphas_bar[:-1]])\n",
    "betas_tilde = betas * (1 - alphas_bar_previous) / (1 - alphas_bar)\n",
    "\n",
    "\n",
    "model = UViT(\n",
    "    img_size=32,\n",
    "    patch_size=2,\n",
    "    embed_dim=512,\n",
    "    depth=12,\n",
    "    num_heads=8,\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=False,\n",
    "    mlp_time_embed=False,\n",
    "    num_classes=-1,\n",
    ")\n",
    "model = OldEarlyExitUViT(uvit=model, classifier_type=\"attention_probe\",exit_threshold=float(\"-inf\"))\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\"./checkpoints/frozenBackbone_attention_3losses.pth\", device)[\n",
    "        \"model_state_dict\"\n",
    "    ]\n",
    ")\n",
    "model = model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "\n",
    "def sample(threshold):\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    x = torch.randn(bs, 3, 32, 32).to(device)\n",
    "    error_prediction_by_timestep = torch.zeros(1000, 13)\n",
    "    indices_by_timestep = torch.zeros(1000, bs)\n",
    "    for t in tqdm(range(999, -1, -1)):\n",
    "        with torch.no_grad():\n",
    "            time_tensor = t * torch.ones(bs, device=device)\n",
    "            epsilon, classifier_outputs, outputs = model(x, time_tensor)\n",
    "\n",
    "        outputs = torch.stack(outputs + [epsilon])\n",
    "        classifier_outputs = torch.stack(\n",
    "            classifier_outputs + [torch.zeros_like(classifier_outputs[0])]\n",
    "        )\n",
    "\n",
    "        # Simulate early exit with a global threshold\n",
    "        indices = torch.argmax((classifier_outputs <= threshold).int(), dim=0)\n",
    "        epsilon = outputs[indices, torch.arange(bs)]\n",
    "\n",
    "        # Log for visualization\n",
    "        error_prediction_by_timestep[t - 1] = classifier_outputs.mean(axis=1)[:13]\n",
    "        indices_by_timestep[t - 1, :] = indices\n",
    "\n",
    "        alpha_t = alphas[t - 1]\n",
    "        alpha_bar_t = alphas_bar[t - 1]\n",
    "        sigma_t = torch.sqrt(betas_tilde[t - 1])\n",
    "\n",
    "        z = torch.randn_like(x) if t > 0 else 0\n",
    "        x = (\n",
    "            torch.sqrt(1 / alpha_t)\n",
    "            * (x - (1 - alpha_t) / (torch.sqrt(1 - alpha_bar_t)) * epsilon)\n",
    "        ) + sigma_t * z\n",
    "\n",
    "    return {\n",
    "        \"samples\": x,\n",
    "        \"error_prediction_by_timestep\": error_prediction_by_timestep,\n",
    "        \"indices_by_timestep\": indices_by_timestep,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_threshold = {\n",
    "    threshold: sample(threshold) for threshold in (0, 0.025, 0.05, 0.075, 0.1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier output plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Make the time be in the \"x-axis\"\n",
    "matrix = results_by_threshold[0][\"error_prediction_by_timestep\"].T\n",
    "# Make time go from T to 0 and\n",
    "# make the first layer be down, and the last layer up\n",
    "matrix = matrix.flip(dims=(0, 1))\n",
    "# Since the dimensions are (13, 1000), we will repeat each row 100 times\n",
    "matrix = matrix.repeat_interleave(repeats=100, dim=0)\n",
    "print(matrix.shape)\n",
    "\n",
    "plt.title(\"Early-exit classifier output\")\n",
    "plt.imshow(matrix)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.xticks(\n",
    "    ticks=np.arange(0, 1001, 200),\n",
    "    labels=np.arange(1000, -1, -200),\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Layer\")\n",
    "plt.yticks(\n",
    "    ticks=np.arange(100, 1301, 100) - 50,\n",
    "    labels=np.arange(13, 0, -1),\n",
    ")\n",
    "\n",
    "plt.colorbar()\n",
    "plt.savefig(\"out_images/classifier_output.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early-exit layer plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Early-exit layer w.r.t. timestep\")\n",
    "time = np.arange(1000, 0, -1)\n",
    "\n",
    "\n",
    "for threshold, results in results_by_threshold.items():\n",
    "    if threshold == 0:\n",
    "        continue\n",
    "    indices_by_timestep = results[\"indices_by_timestep\"]\n",
    "    mean = indices_by_timestep.mean(axis=1)\n",
    "    std = indices_by_timestep.std(axis=1)\n",
    "\n",
    "    plt.plot(time, mean, label=f\"Threshold = {threshold}\")\n",
    "    plt.fill_between(time, mean - std, mean + std, alpha=0.1)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.xticks(\n",
    "    ticks=np.arange(0, 1001, 200),\n",
    "    labels=np.arange(1000, -1, -200),\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Layer\")\n",
    "plt.savefig(\"out_images/exit_layer.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "num_thresholds = len(results_by_threshold)\n",
    "\n",
    "final_image = []\n",
    "for threshold, results in results_by_threshold.items():\n",
    "    samples = results[\"samples\"]\n",
    "    samples = samples.cpu().numpy()\n",
    "    samples = (samples + 1) / 2\n",
    "    # Stack samples \"horizontally\"\n",
    "    samples = rearrange(samples, \"b c h w -> h (b w) c\")\n",
    "    final_image.append(samples)\n",
    "\n",
    "# Stack vertically\n",
    "final_image = np.concatenate(final_image)\n",
    "final_image = np.clip(final_image, 0, 1)\n",
    "\n",
    "plt.title(\"Samples\")\n",
    "plt.imshow(final_image)\n",
    "\n",
    "plt.xticks([], [])\n",
    "\n",
    "plt.yticks(np.arange(0, 32 * num_thresholds, 32) + 16, results_by_threshold.keys())\n",
    "plt.ylabel(\"Threshold\")\n",
    "plt.savefig(\"out_images/samples.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
